\documentclass{article}

\usepackage{times}
\usepackage{amssymb, amsmath, amsthm}
\usepackage[margin=.5in]{geometry}
\usepackage{graphicx}
\usepackage[linewidth=1pt]{mdframed}

\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}

\newcommand{\incfig}[1]{
    \def\svgwidth{\columnwidth}
    \import{./figures/}{#1.pdf_tex}
}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem*{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\begin{document}

\title{Mathematical Statistics - Assignment 8}
\author{Philip Warton}
\date{\today}
\maketitle

\section*{Problem 5.9}
    Let $Y_1$ and $Y_2$ have the joint probability density function given by
    \[
        f(y_1,y_2) =
        \begin{cases}
            k(1-y_2) & 0 \leqslant y_1 \leqslant y_2 \leqslant 1 \\
            0 & \text{otherwise}
        \end{cases}
    \]

    \subsection*{(a)}
        Find the value of $k$ that makes this a probability density function. \\\\
        We want to find some value of $k$ such that the double integral on $\mathbb{R}^2$
        evaluates to 1. We write:

        \begin{align*}
            1 &= \int_{-\infty}^\infty \int_{-\infty}^\infty f(y_1,y_2) dy_1 dy_2 \\
              &= \int_0^1 \int_0^{y_2} k(1-y_2) dy_1 dy_2 \\
              &= \int_0^1 \left[ k y_1 (1 - y_2) \right]_0^{y_2} dy_2 \\
              &= \int_0^1 k y_2 - k y_2^2 dy_2 \\
              &= \left[ \frac{k y_2^2}{2} - \frac{k y_2^3}{3} \right]_0^1 \\
              &= \frac{k}{2} - \frac{k}{3} \\
            \Longrightarrow 
            6 &= 3k - 2k \\
              & = k
        \end{align*}

    \subsection*{(b)}
        Find $P(Y_1 \leqslant \frac{3}{4}, Y_2 \geqslant \frac{1}{2})$. \\\\
        We can rewrite this as $P(Y_2 \geqslant \frac{1}{2}) - P(Y_1 > \frac{3}{4})$.
        Then this becomes an integral that we can compute:

        \begin{align*}
            P(Y_2 \geqslant \frac{1}{2}) - P(Y_1 > \frac{3}{4})
            &= \int_\frac{1}{2}^1 \int_0^{y_2} f(y_1,y_2) dy_1 dy_2 - 
               \int_\frac{3}{4}^1 \int_{y_1}^1 f(y_1,y_2) dy_2 dy_1 \\
            &= \int_\frac{1}{2}^1 \int_0^{y_2} 6(1 - y_2) dy_1 dy_2 - 
               \int_\frac{3}{4}^1 \int_{y_1}^1 6(1 - y_2) dy_2 dy_1 \\
            &= \int_{\frac{1}{2}}^1 \left[6y_1(1 - y_2)\right]_0^{y_2} dy_2 -
               \int_{\frac{3}{4}}^1 \int_{y_1}^1 6(1 - y_2) dy_2 dy_1 \\
            &= \int_\frac{1}{2}^1 6y_2 - 6y_2^2 dy_2 - 
               \int_{\frac{3}{4}}^1 \int_{y_1}^1 6(1 - y_2) dy_2 dy_1 \\
            &= \left[ 3y_2^2 - 2y_2^3 \right]_\frac{1}{2}^1 - 
               \int_{\frac{3}{4}}^1 \int_{y_1}^1 6(1 - y_2) dy_2 dy_1 \\
            &= [3 - 2] - [\frac{3}{4} - \frac{1}{4}] - 
               \int_{\frac{3}{4}}^1 \int_{y_1}^1 6(1 - y_2) dy_2 dy_1 \\
            &= \frac{1}{2} - \int_{\frac{3}{4}}^1 \int_{y_1}^1 6(1 - y_2) dy_2 dy_1 \\
            &= \frac{1}{2} - \int_{\frac{3}{4}}^1 6y_2 - 3y_2^2 \bigg|_{y_1}^1 dy_1\\
            &= \frac{1}{2} - \int_{\frac{3}{4}}^1 [6 - 3] - [6y_1 - 3y_1^2] dy_1\\
            &= \frac{1}{2} - \int_{\frac{3}{4}}^1 3 - 6y_1 + 3y_1^2 dy_1 \\
            &= \frac{1}{2} - \left[3y_1 - 3y_1^2 + y_1^3 \right]_\frac{3}{4}^1\\
            &= \frac{1}{2} - \left([3 - 3 + 1] - \left[\frac{9}{4} - \frac{27}{16} + \frac{27}{64}\right]\right)\\
            &= \frac{1}{2} - \frac{1}{64} = \frac{31}{64}
        \end{align*}

\section*{Problem 5.16}
    \[
        f(y_1,y_2) =
        \begin{cases}
            y_1 + y_2 & y_1,y_2 \in [0,1]\\
            0 & \text{otherwise}
        \end{cases}
    \]

    \subsection*{(a)}
        \begin{align*}
            P(Y_1 < 1 / 2, Y_2 > 1 / 4)
            &= \int_\frac{1}{4}^1 \int_0^\frac{1}{2} y_1 + y_2 dy_1 dy_2 \\
            &= \int_\frac{1}{4}^1 \frac{y_1^2}{2} + y_2 y_1 \bigg|_0^\frac{1}{2} dy_2 \\
            &= \int_\frac{1}{4}^1 \frac{1}{8} + \frac{y_2}{2} dy_2 \\
            &= \frac{y_2}{8} + \frac{y_2^2}{4} \bigg|_\frac{1}{4}^1\\
            &= \frac{1}{8} + \frac{1}{4} - [\frac{1}{32} + \frac{1}{64}]\\
            &= \frac{3}{8} - [\frac{3}{64}] = \frac{21}{64}
        \end{align*}

    \subsection*{(b)}
        \begin{align*}
            P(Y_1 + Y_2 \leqslant 1) &= P(Y_1 \leqslant 1 - Y_2) \\
            &= \int_0^1 \int_0^{1 - y_2} y_1 + y_2 dy_1 dy_2 \\
            &= \int_0^1 \frac{y_1^2}{2} + y_1 y_2 \bigg|_0^{1 - y_2} dy_2 \\
            &= \int_0^1 \frac{(1-y_2)^2}{2} + (1-y_2) y_2  dy_2 \\
            &= \int_0^1 \frac{1 -2y_2 + y_2^2}{2} + y_2 - y_2^2 dy_2 \\
            &= \int_0^1 \frac{1}{2} - y_2 + \frac{1}{2}y_2^2 + y_2 - y_2^2 dy_2 \\
            &= \int_0^1 \frac{1}{2} - \frac{1}{2}y_2^2 dy_2 \\
            &= \frac{1}{2} \int_0^1 1 - y_2^2 dy_2 \\
            &= \frac{1}{2} \left[y_2 - \frac{y_2^3}{3} \right]_0^1 \\
            &= \frac{1}{2} \frac{2}{3} = \frac{1}{3}
        \end{align*}

\section*{Problem 5.24}
    \[
        f(y_1, y_2) = 
        \begin{cases}
            1 & y_1,y_2 \in [0,1]\\
            0 & \text{otherwise}
        \end{cases}
    \]

    \subsection*{(a)} Find the marginal denisty functions for $Y_1, Y_2$.
        \begin{align*}
            f_1(y_1) &= 
            \begin{cases}
                \int_0^1 1 dy_2 = 1 & 0 \leqslant y_2 \leqslant 1 \\
                0 & \text{otherwise}    
            \end{cases}\\\\
            f_2(y_2) &= 
            \begin{cases}
                \int_0^1 1 dy_1 = 1 & 0 \leqslant y_1 \leqslant 1 \\
                0 & \text{otherwise}    
            \end{cases}
        \end{align*}

    \subsection*{(b)}
        \begin{align*}
            P(.3 < Y_1 < .5) &= \int_{.3}^{.5} f_1(y_1) dy_1 \\
            &= \int_{.3}^{.5} 1 dy_1 \\ &= .5 - .3 = .2\\\\
            P(.3 < Y_2 < .5) &= \int_{.3}^{.5} f_2(y_2) dy_2 \\
            &= \int_{.3}^{.5} 1 dy_1 \\ &= .5 - .3 = .2\\
        \end{align*}

    \subsection*{(c)}
        We know that 
        \[
            f(y_1|y_2) = \frac{f(y_1, y_2)}{f_2(y_2)} = \frac{1}{1} = 1
        \]
        So this is defined everywhere for every $y_2 \in [0,1]$. Otherwise, $f_2$ is 0 which 
        is clearly undefined.

    \subsection*{(d)}
        From part $c$, we know that for any $y_2 \in [0,1]$ that $f(y_1|y_2) = 1$ for all $y_1 \in [0,1]$.
    
    \subsection*{(e)}
        \[
            P(.3 < Y_1 < .5 | Y_2 = .3) = \int_{.3}^{.5} 1 dy_1 = .5 - .3 = .2
        \]

    \subsection*{(f)}
        \[
            P(.3 < Y_1 < .5 | Y_2 = .5) = \int_{.3}^{.5} 1 dy_1 = .5 - .3 = .2
        \]

    \subsection*{(g)}
        The answer does not change at all, this is probably because of the fact that the density 
        function is trivial, and the variables are independent.

\section*{Problem 5.38}
    The variable $Y_1$ is uniform over $0 \leqslant y_1 \leqslant 1$. The variable $Y_2$ is uniform 
    over $0 \leqslant y_2 \leqslant y_1$.

    \subsection*{(a)}
        \[
            f(y_1,y_2) = \begin{cases}
                1 & 0 \leqslant y_2 \leqslant y_1 \leqslant 1\\
                0 & \text{otherwise}
            \end{cases}
        \]

    \subsection*{(b)}
        $f_1(y_1) = \int_0^{y_1} 1 dy_2 = y_1, \forall y_1 \in [0,1]$.
        \begin{align*}
            P(Y_2 > 1/4 | Y_1 = 1/2) &= \int_{1/4}^1 f(y_2|y_1 = 1/2) dy_2\\
            &= \int_{1/4}^1 \frac{1}{(1 / 2)}dy_2 =1 - \frac{1}{4} = \frac{3}{4}
        \end{align*}

\section*{Problem 5.48}
    No, these variables are not independent. The probability $P(Y_1 = 1) = .24$ whereas $P(Y_1 = 1 | Y_2 = 1) = \frac{.02}{.16} = .125$.

\section*{Problem 5.68}
    \subsection*{(a)}
        We say $g(y_1) = {2 \choose y_1}.2^{y_1} .8^{2 - y_1}, h(y_2) = {1 \choose y_2}.3^{y_2} .7^{1 - y_2}$.
        Then since they are independent the joint density function will be the product of these functions.
        \[
            f(y_1,y_2) = \left({2 \choose y_1}.2^{y_1} .8^{2 - y_1}\right)\left({1 \choose y_2}.3^{y_2} .7^{1 - y_2}\right)
        \]

    \subsection*{(b)}
        \begin{align*}
            P(Y_1 + Y_2 \leqslant 1) &= f(0,0) + f(0,1) + f(1,0) \\
            &= (.8^2)(.7) + (.8^2)(.3) + 2(.2)(.8)(.7) \\
            &= .864
        \end{align*}

\section*{Problem 5.72}
    
    \subsection*{(a)}
        \[
            E(Y_1) = np = 2\frac{1}{3} = \frac{2}{3}
        \]
    \subsection*{(b)}
        \[
            V(Y_1) = np(1-p) = 2 \frac{2}{3} \frac{1}{3} = \frac{4}{9}
        \]
    \subsection*{(c)}
        \[
            E(Y_1 - Y_2) = E(Y_1) - E(Y_2) = \frac{2}{3} - \frac{2}{3} = 0
        \]

\section*{Problem 5.84}
    \subsection*{(a)}
        \begin{align*}
            E(Y_1) &= \frac{p}{q}\\
            E(Y_2) &= \frac{p}{q}\\
            E(Y_1 - Y_2) &= E(Y_1) - E(Y_2) = 0
        \end{align*}
    \subsection*{(b)}
        \begin{align*}
            E(Y_1^2) &= p\left(\frac{2}{q^2} - \frac{1}{q}\right)\\
            E(Y_2^2) &= p\left(\frac{2}{q^2} - \frac{1}{q}\right)\\
            E(Y_1 Y_2) &=E(Y_1)E(Y_2) = \frac{p^2}{q^2}
        \end{align*}
    \subsection*{(c)}
        \[
            E(Y_1-Y_2)^2 = 0
        \]
        \begin{align*}
            V(Y_1 - Y_2) &= E((Y_1-Y_2)^2) - 0 \\
            &= E(Y_1^2 - 2Y_1Y_2 + Y_2^2)\\
            & = E(Y_1^2) + E(Y_2^2) - 2E(Y_1Y_2)\\
            &= 2p\left(\frac{2}{q^2} - \frac{1}{q}\right) - 2\frac{p^2}{q^2}\\
            &= \frac{2p}{q}\left(\frac{2}{q} - 1 - \frac{p}{q}\right)
        \end{align*}
\section*{Problem 5.94}
    \subsection*{(a)}
        \begin{align*}
            Cov(U_1, U_2) & = E(U_1 U_2) - E(U_1)E(U_2) \\
            &= E([Y_1 + Y_2][Y_1 - Y_2]) - E(Y_1 + Y_2)E(Y_1 - Y_2) \\
            &= E(Y_1^2 - Y_2^2) - [E(Y_1) + E(Y_2)][E(Y_1) - E(Y_2)]\\
            &=E(Y_1^2) - E(Y_2^2) - E(Y_1)^2 + E(Y_2)^2\\
            &= V(Y_1) - V(Y_2)
        \end{align*}
    \subsection*{(b)}
        \begin{align*}
            \rho & = \frac{Cov(U_1, U_2)}{\sqrt{V(U_1)}\sqrt{V(U_2)}} \\
            & = \frac{V(Y_1) - V(Y_2)}{\sqrt{V(Y_1 + Y_2)V(Y_1 - Y_2)}}\\
            &= \frac{V(Y_1) - V(Y_2)}{\sqrt{(V(Y_1) + V(Y_2) + 2Cov(Y_1,Y_2))(V(Y_1) + V(Y_2) - 2Cov(Y_1,Y_2))}} \\
            &= \frac{V(Y_1)- V(Y_2)}{\sqrt{(V(Y_1) + V(Y_2))(V(Y_1) + V(Y_2))}}\\
            &= \frac{V(Y_1) - V(Y_2)}{V(Y_1) + V(Y_2)}
        \end{align*}
    \subsection*{(c)}
        It is possible that this coviariance is equal to 0. This is the case when
        both variables $Y_1$ and $Y_2$ have the same variance.
\section*{Problem 5.100}
    \subsection*{(a)}
        We have $E(Y_1) = E(Z) = 0$. Then we have $E(Y_2) = E(Z^2) = V(Z) + E(Z)^2 = \sigma^2 + 0^2 = 1$.
    \subsection*{(b)}
        Now we have $E(Y_1Y_2) = E(Z Z^2) = E(Z^3) = \frac{1}{\sqrt{2\pi}} \int_\mathbb{R} x^3 e^{-\frac{x^2}{2}}dx = 0$.
    \subsection*{(c)}
        \[
            Cov(Y_1,Y_2) = Cov(Z,Z^2) = E(ZZ^2) - E(Z)E(Z^2) = 0 - 0(1) = 0
        \]
    \subsection*{(d)}
        So we konw that $P(Y_2 > 1 | Y_1 > 1) = P(Z^2 > 1 | Z > 1) = 1$. However since both, $P(Z^2 > 1)$ and $P(Z > 1)$ are 
        stricly smaller than 1 (in fact most of the normal probability lies between -1 and 1), we know that $P(Z^2>1)P(Z>1)$ 
        must also lie in $(0,1)$ which does not contain 1, therefore $P(Z^2 > 1 | Z > 1) \neq P(Z^2>1)P(Z>1)$. The two are not 
        independent.
\end{document}
